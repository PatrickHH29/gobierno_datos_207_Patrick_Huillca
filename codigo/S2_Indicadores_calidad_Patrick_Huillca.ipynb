{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actividad 01**\n",
    "Alumno: Huillca Herrera Patrick David"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos una consulta a la apinews para ver noticias recientes para evaluar los datos definimos cuatro indicadores de calidad\n",
    "- Completitud de que todas las noticias tengan al menos un autor\n",
    "- Completitud que las noticias tengan al menos una fuente\n",
    "- Noticias recientes: Que nos presente noticias de a lo mas 3 d√≠as de antiguedad\n",
    "- Que tengan una descripci√≥n valida: Que las noticias como m√≠nimo tengan una descripci√≥n de 2 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas de Noticias:\n",
      "Total de noticias obtenidas: 99\n",
      "Noticias con al menos un autor: 97 (97.98%)\n",
      "Noticias con fuente: 99 (100.00%)\n",
      "Noticias con antig√ºedad de m√°ximo 3 d√≠as: 10 (10.10%)\n",
      "Noticias con descripci√≥n de al menos 2 palabras: 94 (94.95%)\n",
      "Datos exportados a 'noticias_peru_listado.csv' y m√©tricas a 'noticias_peru_metrics.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "# URL de la API de NewsAPI para buscar noticias sobre Per√∫\n",
    "url = f'https://newsapi.org/v2/everything?q=Per√∫&apiKey={api_key}'\n",
    "\n",
    "# Realizar la solicitud GET\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificamos si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    news_data = response.json()\n",
    "\n",
    "    # Fecha actual y fecha l√≠mite para las noticias (3 d√≠as atr√°s)\n",
    "    today = datetime.today()\n",
    "    three_days_ago = today - timedelta(days=3)\n",
    "\n",
    "    # Variables para las m√©tricas\n",
    "    total_articles = len(news_data['articles'])\n",
    "    articles_with_author = 0\n",
    "    articles_with_source = 0\n",
    "    articles_recent = 0\n",
    "    articles_with_description = 0\n",
    "\n",
    "    # Lista para almacenar las noticias filtradas\n",
    "    filtered_articles = []\n",
    "\n",
    "    # Filtrar noticias y calcular m√©tricas\n",
    "    for article in news_data['articles']:\n",
    "        published_at = article.get('publishedAt', '')\n",
    "        description = article.get('description', '')\n",
    "        author = article.get('author', None)\n",
    "        source = article.get('source', {}).get('name', None)\n",
    "\n",
    "        # Fecha de publicaci√≥n\n",
    "        published_date = datetime.strptime(published_at, '%Y-%m-%dT%H:%M:%SZ') if published_at else None\n",
    "\n",
    "        # Filtrar noticias recientes (hasta 3 d√≠as)\n",
    "        if published_date and published_date >= three_days_ago:\n",
    "            articles_recent += 1\n",
    "\n",
    "        # Verificar si tiene autor\n",
    "        if author:\n",
    "            articles_with_author += 1\n",
    "\n",
    "        # Verificar si tiene fuente\n",
    "        if source:\n",
    "            articles_with_source += 1\n",
    "\n",
    "        # Verificar si la descripci√≥n tiene al menos 2 palabras\n",
    "        if len(description.split()) >= 2:\n",
    "            articles_with_description += 1\n",
    "\n",
    "        # Agregar la noticia al listado de noticias filtradas\n",
    "        filtered_articles.append({\n",
    "            'Title': article['title'],\n",
    "            'Description': description,\n",
    "            'Source': source,\n",
    "            'Author': author if author else 'Unknown',\n",
    "            'PublishedAt': published_at,\n",
    "            'URL': article['url']\n",
    "        })\n",
    "\n",
    "    # Calcular m√©tricas\n",
    "    percent_with_author = (articles_with_author / total_articles) * 100 if total_articles > 0 else 0\n",
    "    percent_with_source = (articles_with_source / total_articles) * 100 if total_articles > 0 else 0\n",
    "    percent_recent = (articles_recent / total_articles) * 100 if total_articles > 0 else 0\n",
    "    percent_with_description = (articles_with_description / total_articles) * 100 if total_articles > 0 else 0\n",
    "\n",
    "    # Mostrar m√©tricas\n",
    "    print(f'M√©tricas de Noticias:')\n",
    "    print(f'Total de noticias obtenidas: {total_articles}')\n",
    "    print(f'Noticias con al menos un autor: {articles_with_author} ({percent_with_author:.2f}%)')\n",
    "    print(f'Noticias con fuente: {articles_with_source} ({percent_with_source:.2f}%)')\n",
    "    print(f'Noticias con antig√ºedad de m√°ximo 3 d√≠as: {articles_recent} ({percent_recent:.2f}%)')\n",
    "    print(f'Noticias con descripci√≥n de al menos 2 palabras: {articles_with_description} ({percent_with_description:.2f}%)')\n",
    "\n",
    "    # Usar pandas para crear el DataFrame y exportar a CSV\n",
    "    news_df = pd.DataFrame(filtered_articles)\n",
    "\n",
    "    # Exportar el DataFrame a un archivo CSV\n",
    "    news_df.to_excel('noticias_peru.xlsx', encoding='utf-8')\n",
    "\n",
    "    # Exportar las m√©tricas a un archivo CSV con pandas\n",
    "    metrics = {\n",
    "        'Metric': ['Total Articles', 'Articles with Author', 'Articles with Source',\n",
    "                   'Articles with Recent Date (< 3 days)', 'Articles with Description (2+ words)',\n",
    "                   'Percentage with Author', 'Percentage with Source',\n",
    "                   'Percentage with Recent Date (< 3 days)', 'Percentage with Description (2+ words)'],\n",
    "        'Value': [total_articles, articles_with_author, articles_with_source,\n",
    "                  articles_recent, articles_with_description,\n",
    "                  f'{percent_with_author:.2f}%', f'{percent_with_source:.2f}%',\n",
    "                  f'{percent_recent:.2f}%', f'{percent_with_description:.2f}%']\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "    # Exportar las m√©tricas a CSV\n",
    "    metrics_df.to_csv('noticias_peru_metrics.xlsx', index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"Datos exportados a 'noticias_peru_listado.csv' y m√©tricas a 'noticias_peru_metrics.csv'.\")\n",
    "else:\n",
    "    print(f'Error al obtener las noticias: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Source</th>\n",
       "      <th>Author</th>\n",
       "      <th>PublishedAt</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cerveza psicod√©lica: el ¬´truco¬ª que usaban en ...</td>\n",
       "      <td>En 2022 se public√≥ un estudio en el que se hab...</td>\n",
       "      <td>Hipertextual</td>\n",
       "      <td>Azucena Mart√≠n</td>\n",
       "      <td>2025-03-25T11:12:58Z</td>\n",
       "      <td>http://hipertextual.com/2025/03/cerveza-psicod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN DIRECTO: Presentaci√≥n oficial de la Nintend...</td>\n",
       "      <td>Hoy es el d√≠a, Nintendo lo tiene todo preparad...</td>\n",
       "      <td>Hipertextual</td>\n",
       "      <td>Alberto Mart√≠n</td>\n",
       "      <td>2025-04-02T12:33:30Z</td>\n",
       "      <td>http://hipertextual.com/2025/04/directo-ninten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El adi√≥s latinoamericano de Telef√≥nica: Murtra...</td>\n",
       "      <td>Telef√≥nica est√° ejecutando una salida acelerad...</td>\n",
       "      <td>Xataka.com</td>\n",
       "      <td>Javier Lacort</td>\n",
       "      <td>2025-03-13T07:00:42Z</td>\n",
       "      <td>https://www.xataka.com/empresas-y-economia/adi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nintendo Switch 2: sigue en directo la present...</td>\n",
       "      <td>Lleg√≥ el d√≠a. Los nintenderos estamos de celeb...</td>\n",
       "      <td>Xataka.com</td>\n",
       "      <td>Ricardo Aguilar</td>\n",
       "      <td>2025-04-02T08:36:00Z</td>\n",
       "      <td>https://www.xataka.com/nuevo/nintendo-switch-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Descubrimiento arqueol√≥gico en Per√∫ desaf√≠a lo...</td>\n",
       "      <td>Un mural de 1.500 a√±os ha salido a la luz en P...</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Lucas Handley</td>\n",
       "      <td>2025-03-09T15:41:47Z</td>\n",
       "      <td>https://es.gizmodo.com/descubrimiento-arqueolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Cu√°les son los partidos de Venezuela en esta v...</td>\n",
       "      <td>A pesar del mal momento y la gran cantidad de ...</td>\n",
       "      <td>La Nacion</td>\n",
       "      <td>LA NACION</td>\n",
       "      <td>2025-03-20T12:32:00Z</td>\n",
       "      <td>https://www.lanacion.com.ar/estados-unidos/cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>La Princesa Leonor estudia las cartas de naveg...</td>\n",
       "      <td>El Juan Sebasti√°n Elcano se encuentra en el es...</td>\n",
       "      <td>El Mundo</td>\n",
       "      <td>Marina Pina</td>\n",
       "      <td>2025-03-25T16:49:25Z</td>\n",
       "      <td>https://www.elmundo.es/espana/2025/03/25/67e2d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cincuenta a√±os en la escena del metal y se vue...</td>\n",
       "      <td>En el mundo de internet es muy com√∫n que las c...</td>\n",
       "      <td>Trendencias.com</td>\n",
       "      <td>Joel Calata</td>\n",
       "      <td>2025-03-06T16:00:13Z</td>\n",
       "      <td>https://www.trendencias.com/mexico/cincuenta-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Advertencia por cantos racistas y discriminato...</td>\n",
       "      <td>Infortunadamente, en cada partido de la Selecc...</td>\n",
       "      <td>Marca</td>\n",
       "      <td>marca.com</td>\n",
       "      <td>2025-03-24T21:12:56Z</td>\n",
       "      <td>https://www.marca.com/co/2025/03/24/67e1c5c826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Al \"chocoapocalipsis\" s√≥lo le faltaba un enemi...</td>\n",
       "      <td>2025 est√° siendo un a√±o nefasto para los amant...</td>\n",
       "      <td>Xataka.com</td>\n",
       "      <td>Alejandro Alcolea</td>\n",
       "      <td>2025-03-09T12:30:12Z</td>\n",
       "      <td>https://www.xataka.com/ecologia-y-naturaleza/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Cerveza psicod√©lica: el ¬´truco¬ª que usaban en ...   \n",
       "1   EN DIRECTO: Presentaci√≥n oficial de la Nintend...   \n",
       "2   El adi√≥s latinoamericano de Telef√≥nica: Murtra...   \n",
       "3   Nintendo Switch 2: sigue en directo la present...   \n",
       "4   Descubrimiento arqueol√≥gico en Per√∫ desaf√≠a lo...   \n",
       "..                                                ...   \n",
       "94  Cu√°les son los partidos de Venezuela en esta v...   \n",
       "95  La Princesa Leonor estudia las cartas de naveg...   \n",
       "96  Cincuenta a√±os en la escena del metal y se vue...   \n",
       "97  Advertencia por cantos racistas y discriminato...   \n",
       "98  Al \"chocoapocalipsis\" s√≥lo le faltaba un enemi...   \n",
       "\n",
       "                                          Description           Source  \\\n",
       "0   En 2022 se public√≥ un estudio en el que se hab...     Hipertextual   \n",
       "1   Hoy es el d√≠a, Nintendo lo tiene todo preparad...     Hipertextual   \n",
       "2   Telef√≥nica est√° ejecutando una salida acelerad...       Xataka.com   \n",
       "3   Lleg√≥ el d√≠a. Los nintenderos estamos de celeb...       Xataka.com   \n",
       "4   Un mural de 1.500 a√±os ha salido a la luz en P...      Gizmodo.com   \n",
       "..                                                ...              ...   \n",
       "94  A pesar del mal momento y la gran cantidad de ...        La Nacion   \n",
       "95  El Juan Sebasti√°n Elcano se encuentra en el es...         El Mundo   \n",
       "96  En el mundo de internet es muy com√∫n que las c...  Trendencias.com   \n",
       "97  Infortunadamente, en cada partido de la Selecc...            Marca   \n",
       "98  2025 est√° siendo un a√±o nefasto para los amant...       Xataka.com   \n",
       "\n",
       "               Author           PublishedAt  \\\n",
       "0      Azucena Mart√≠n  2025-03-25T11:12:58Z   \n",
       "1      Alberto Mart√≠n  2025-04-02T12:33:30Z   \n",
       "2       Javier Lacort  2025-03-13T07:00:42Z   \n",
       "3     Ricardo Aguilar  2025-04-02T08:36:00Z   \n",
       "4       Lucas Handley  2025-03-09T15:41:47Z   \n",
       "..                ...                   ...   \n",
       "94          LA NACION  2025-03-20T12:32:00Z   \n",
       "95        Marina Pina  2025-03-25T16:49:25Z   \n",
       "96        Joel Calata  2025-03-06T16:00:13Z   \n",
       "97          marca.com  2025-03-24T21:12:56Z   \n",
       "98  Alejandro Alcolea  2025-03-09T12:30:12Z   \n",
       "\n",
       "                                                  URL  \n",
       "0   http://hipertextual.com/2025/03/cerveza-psicod...  \n",
       "1   http://hipertextual.com/2025/04/directo-ninten...  \n",
       "2   https://www.xataka.com/empresas-y-economia/adi...  \n",
       "3   https://www.xataka.com/nuevo/nintendo-switch-2...  \n",
       "4   https://es.gizmodo.com/descubrimiento-arqueolo...  \n",
       "..                                                ...  \n",
       "94  https://www.lanacion.com.ar/estados-unidos/cua...  \n",
       "95  https://www.elmundo.es/espana/2025/03/25/67e2d...  \n",
       "96  https://www.trendencias.com/mexico/cincuenta-a...  \n",
       "97  https://www.marca.com/co/2025/03/24/67e1c5c826...  \n",
       "98  https://www.xataka.com/ecologia-y-naturaleza/a...  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos una consulta a la apiweather para ver la temperatura de 4 departamentos del pa√≠s (m√≠nima y m√°xima del dia) para evaluar los datos definimos cuatro indicadores de calidad\n",
    "- Completitud que esten las temperaturas de los 4 departamentos a la fecha de hoy\n",
    "- Que la temperatura maxima no sea menor a la temperatura m√≠nima (coherencia de la data)\n",
    "- Que los valores de termperatura sean de tipo float para su uso y comparaci√≥n con otras temperaturas (que no sean valor string)\n",
    "- Que todos los registros tengan los datos de temperatura m√≠nima y m√°xima completa (que no falte ninguno de esos datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de las columnas:\n",
      "City         object\n",
      "Date         object\n",
      "Temp_Max    float64\n",
      "Temp_Min    float64\n",
      "dtype: object\n",
      "\n",
      "Total de registros: 4\n",
      "\n",
      "N√∫mero de filas donde falta Temp_Max o Temp_Min: 0 (0.00%)\n",
      "N√∫mero de filas donde Temp_Max < Temp_Min: 0 (0.00%)\n",
      "N√∫mero de filas vac√≠as: 0 (0.00%)\n",
      "N√∫mero de registros donde Temp_Max es float: 4 (100.00%)\n",
      "N√∫mero de registros donde Temp_Min es float: 4 (100.00%)\n",
      "\n",
      "Los datos clim√°ticos de las ciudades en Per√∫ han sido exportados a 'clima_peru_weatherapi_limpio.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Tu clave API de WeatherAPI (c√°mbiala por la tuya)\n",
    "\n",
    "\n",
    "# Coordenadas de las ciudades en Per√∫\n",
    "cities_coordinates = {\n",
    "    'Lima': {'lat': -12.0464, 'lon': -77.0428},\n",
    "    'Arequipa': {'lat': -16.4090, 'lon': -71.5375},\n",
    "    'Cusco': {'lat': -13.5320, 'lon': -71.9675},\n",
    "    'Trujillo': {'lat': -8.1103, 'lon': -79.0193}\n",
    "}\n",
    "\n",
    "# Lista para almacenar los registros\n",
    "records = []\n",
    "\n",
    "# Realizamos la solicitud para cada ciudad\n",
    "for city, coords in cities_coordinates.items():\n",
    "    # URL de la API de WeatherAPI para obtener los datos clim√°ticos (temperatura m√≠nima y m√°xima)\n",
    "    url = f'http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={coords[\"lat\"]},{coords[\"lon\"]}&days=1'\n",
    "\n",
    "    # Realizar la solicitud GET\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Verificamos si la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "\n",
    "        # Extraemos los registros de temperatura m√°xima y m√≠nima por cada d√≠a\n",
    "        if 'forecast' in weather_data and 'forecastday' in weather_data['forecast']:\n",
    "            for daily_data in weather_data['forecast']['forecastday']:\n",
    "                temp_max = daily_data['day']['maxtemp_c']\n",
    "                temp_min = daily_data['day']['mintemp_c']\n",
    "                date = daily_data['date']\n",
    "\n",
    "                # Comprobamos si alguna de las temperaturas es None o vac√≠a\n",
    "                if temp_max is None or temp_min is None:\n",
    "                    continue  # Saltamos el registro si hay valores vac√≠os en alguna de las temperaturas\n",
    "\n",
    "                records.append({\n",
    "                    'City': city,\n",
    "                    'Date': date,\n",
    "                    'Temp_Max': temp_max,\n",
    "                    'Temp_Min': temp_min\n",
    "                })\n",
    "    else:\n",
    "        print(f'Error al obtener los datos del clima para {city}: {response.status_code}')\n",
    "\n",
    "# Crear un DataFrame de Pandas con los registros de las temperaturas\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Mostrar el tipo de datos de las columnas\n",
    "print(\"Tipos de datos de las columnas:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Total de registros\n",
    "total_records = len(df)\n",
    "\n",
    "# 1. N√∫mero de filas donde no haya una temperatura m√°xima o m√≠nima\n",
    "missing_temps = df[df['Temp_Max'].isnull() | df['Temp_Min'].isnull()]\n",
    "missing_temps_count = len(missing_temps)\n",
    "missing_temps_percentage = (missing_temps_count / total_records) * 100\n",
    "\n",
    "# 2. N√∫mero de filas donde la temperatura m√°xima sea menor que la m√≠nima\n",
    "max_less_than_min = len(df[df['Temp_Max'] < df['Temp_Min']])\n",
    "max_less_than_min_percentage = (max_less_than_min / total_records) * 100\n",
    "\n",
    "# 3. Verificar que no haya filas vac√≠as\n",
    "empty_rows = df.isnull().all(axis=1)  # Identifica filas completamente vac√≠as\n",
    "empty_rows_count = empty_rows.sum()\n",
    "empty_rows_percentage = (empty_rows_count / total_records) * 100\n",
    "\n",
    "# 4. Verificar que las temperaturas son de tipo float (y asegurar que no haya otros tipos)\n",
    "temp_max_is_float = df['Temp_Max'].apply(lambda x: isinstance(x, float)).sum()\n",
    "temp_min_is_float = df['Temp_Min'].apply(lambda x: isinstance(x, float)).sum()\n",
    "\n",
    "# Mostrar los resultados de la validaci√≥n\n",
    "print(f'\\nTotal de registros: {total_records}')\n",
    "print(f'\\nN√∫mero de filas donde falta Temp_Max o Temp_Min: {missing_temps_count} ({missing_temps_percentage:.2f}%)')\n",
    "print(f'N√∫mero de filas donde Temp_Max < Temp_Min: {max_less_than_min} ({max_less_than_min_percentage:.2f}%)')\n",
    "print(f'N√∫mero de filas vac√≠as: {empty_rows_count} ({empty_rows_percentage:.2f}%)')\n",
    "print(f'N√∫mero de registros donde Temp_Max es float: {temp_max_is_float} ({(temp_max_is_float / total_records) * 100:.2f}%)')\n",
    "print(f'N√∫mero de registros donde Temp_Min es float: {temp_min_is_float} ({(temp_min_is_float / total_records) * 100:.2f}%)')\n",
    "\n",
    "# Validaci√≥n: Verificar que no haya filas vac√≠as o nulas\n",
    "df_clean = df.dropna(how='all')  # Elimina las filas completamente vac√≠as\n",
    "\n",
    "# Exportar el DataFrame limpio a un archivo CSV con los datos clim√°ticos\n",
    "df_clean.to_csv('clima_peru_weatherapi_limpio.csv', index=False, encoding='utf-8')\n",
    "print(\"\\nLos datos clim√°ticos de las ciudades en Per√∫ han sido exportados a 'clima_peru_weatherapi_limpio.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp_Max</th>\n",
       "      <th>Temp_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lima</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arequipa</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cusco</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>16.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trujillo</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>23.7</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City        Date  Temp_Max  Temp_Min\n",
       "0      Lima  2025-04-04      23.0      19.3\n",
       "1  Arequipa  2025-04-04      20.0       9.7\n",
       "2     Cusco  2025-04-04      16.1       5.8\n",
       "3  Trujillo  2025-04-04      23.7      20.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BASE DE TIPO DE CAMBIO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizar√° la m√©trica completitur porque para cuando uno vende cosas en moneda extranjera se requiere disponer del precio del dolar/euro de manera bien actualizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error en 2024-01-01: 403\n",
      "‚ùå Error en 2024-01-02: 403\n",
      "‚ùå Error en 2024-01-03: 403\n",
      "‚ùå Error en 2024-01-04: 403\n",
      "‚ùå Error en 2024-01-05: 403\n",
      "‚ùå Error en 2024-01-06: 403\n",
      "‚ùå Error en 2024-01-07: 403\n",
      "‚ùå Error en 2024-01-08: 403\n",
      "‚ùå Error en 2024-01-09: 403\n",
      "‚ùå Error en 2024-01-10: 403\n",
      "‚ùå Error en 2024-01-11: 403\n",
      "‚ùå Error en 2024-01-12: 403\n",
      "‚ùå Error en 2024-01-13: 403\n",
      "‚ùå Error en 2024-01-14: 403\n",
      "‚ùå Error en 2024-01-15: 403\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Fecha'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# === CREAR DATAFRAME ===\u001b[39;00m\n\u001b[0;32m     49\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(registros)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFecha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# === COMPLETITUD ===\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5500\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5497\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m   5499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 5500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   5503\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Fecha'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "\n",
    "base_currency = \"USD\"\n",
    "target_currency = \"EUR\"\n",
    "start_date = \"2024-01-01\"\n",
    "end_date = \"2024-01-15\"  # Puedes extenderlo, pero cuidado con el rate limit\n",
    "\n",
    "# === PREPARAR FECHAS ===\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# === OBTENER DATOS ===\n",
    "registros = []\n",
    "\n",
    "for fecha in date_range:\n",
    "    fecha_str = fecha.strftime('%Y-%m-%d')\n",
    "    url = f\"https://api.fastforex.io/historical\"\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"date\": fecha_str,\n",
    "        \"from\": base_currency,\n",
    "        \"to\": target_currency\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"‚ùå Error en {fecha_str}: {response.status_code}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        data = response.json()\n",
    "        rate = data.get(\"result\", {}).get(target_currency)\n",
    "        registros.append({\n",
    "            \"Fecha\": fecha,\n",
    "            f\"{base_currency}_{target_currency}\": rate\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error procesando {fecha_str}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    time.sleep(1.1)  # üëà Para evitar rate limits (ajusta seg√∫n tu plan)\n",
    "\n",
    "# === CREAR DATAFRAME ===\n",
    "df = pd.DataFrame(registros)\n",
    "df.set_index(\"Fecha\", inplace=True)\n",
    "df = df.sort_index()\n",
    "\n",
    "# === COMPLETITUD ===\n",
    "full_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "df = df.reindex(full_range)\n",
    "\n",
    "total_days = len(full_range)\n",
    "days_with_data = df[f\"{base_currency}_{target_currency}\"].count()\n",
    "missing_days = total_days - days_with_data\n",
    "completeness_pct = (days_with_data / total_days) * 100\n",
    "\n",
    "# === REPORTE ===\n",
    "print(\"\\nüìä M√âTRICAS DE COMPLETITUD\")\n",
    "print(f\"Rango: {start_date} a {end_date}\")\n",
    "print(f\"D√≠as esperados: {total_days}\")\n",
    "print(f\"D√≠as con datos: {days_with_data}\")\n",
    "print(f\"Faltantes: {missing_days}\")\n",
    "print(f\"Completitud: {completeness_pct:.2f}%\")\n",
    "\n",
    "# === EXPORTAR A EXCEL ===\n",
    "df[\"missing\"] = df[f\"{base_currency}_{target_currency}\"].isnull()\n",
    "archivo = f\"reporte_fastforex_{base_currency}_{target_currency}.xlsx\"\n",
    "df.to_excel(archivo, index_label=\"Fecha\")\n",
    "print(f\"\\n‚úÖ Exportado a: {archivo}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
